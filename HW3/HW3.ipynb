{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eGBgThS8q8k3"},"source":["Họ tên: Võ Thành Nam\n","\n","MSSV: 19120301"]},{"cell_type":"markdown","metadata":{"id":"7qdrvDrCrnqz"},"source":["# HW3: Các loại bộ nhớ trong CUDA"]},{"cell_type":"markdown","metadata":{"id":"VKXB0wA7yhq9"},"source":["Với các GPU tương đối mới thì để biên dịch chỉ cần dùng câu lệnh: \\\n","`nvcc tên-file.cu -o tên-file-chạy`\n","\n","Nhưng trên Colab mình thường lấy được GPU khá cũ là Tesla K80 với compute capability (phiên bản phần cứng) là 3.7; để biên dịch đúng với GPU khá cũ này thì bạn cần dùng câu lệnh: \\\n","`nvcc -arch=sm_37 tên-file.cu -o tên-file-chạy` \\\n","Trong đó, 37 chính là compute capability của GPU Tesla K80.\n","\n","Để phòng trường hợp khi làm bài bạn lấy được GPU có compute capability x.x nhưng khi chấm bài Thầy lại lấy được GPU có compute capability khác x.x, dưới đây mình sẽ có đoạn code Python để tự động lấy 2 con số ứng với compute capability của GPU và lưu vào 2 biến `major` và `minor`:\n"]},{"cell_type":"code","metadata":{"id":"bCkmnirl2xWF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669279360503,"user_tz":-420,"elapsed":1645,"user":{"displayName":"Nam Vo","userId":"01521377105719415804"}},"outputId":"16f9415b-4471-4d70-ed07-f3732bc70544"},"source":["from numba import cuda\n","major, minor = cuda.get_current_device().compute_capability\n","print(f'GPU compute capability: {major}.{minor}')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU compute capability: 7.5\n"]}]},{"cell_type":"markdown","metadata":{"id":"Tq1-pmi72yS6"},"source":["Một khi đã chạy đoạn code Python ở trên, để biên dịch thì bạn sẽ dùng câu lệnh: \\\n","`nvcc -arch=sm_{major}{minor} tên-file.cu -o tên-file-chạy`"]},{"cell_type":"markdown","metadata":{"id":"2xCyT0o8Z7nj"},"source":["Dưới đây, khi làm bài thì bạn có thể tùy ý thêm/xóa cell. Đừng xóa mấy cell có chữ của Thầy là được."]},{"cell_type":"code","metadata":{"id":"tbFLx1i4JxIE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669279382635,"user_tz":-420,"elapsed":22135,"user":{"displayName":"Nam Vo","userId":"01521377105719415804"}},"outputId":"bf9c9c22-2742-4707-bd47-84b9cf71bb6d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"aZNqZuECjNso","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669279382635,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nam Vo","userId":"01521377105719415804"}},"outputId":"1537f3b9-f53e-410a-9acf-5d9bc1a7c459"},"source":["# You should change this\n","%cd /content/drive/MyDrive/ParallelProgramming/HW3"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ParallelProgramming/HW3\n"]}]},{"cell_type":"code","metadata":{"id":"NVFUj14OYUyy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669279391256,"user_tz":-420,"elapsed":8623,"user":{"displayName":"Nam Vo","userId":"01521377105719415804"}},"outputId":"f809add5-3f4b-4344-8765-6b55c185cff7"},"source":["!nvcc -arch=sm_{major}{minor} HW3.cu -o HW3\n","!./HW3 in.pnm out.pnm "],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["**********GPU info**********\n","Name: Tesla T4\n","Compute capability: 7.5\n","Num SMs: 40\n","Max num threads per SM: 1024\n","Max num warps per SM: 32\n","GMEM: 15843721216 bytes\n","CMEM: 65536 bytes\n","L2 cache: 4194304 bytes\n","SMEM / one SM: 65536 bytes\n","****************************\n","\n","Image size (width x height): 512 x 512\n","\n","Kernel 1, block size 32x32, grid size 16x16\n","Kernel time: 0.349120 ms\n","Error: 0.000703\n","\n","Kernel 2, block size 32x32, grid size 16x16\n","Kernel time: 0.338624 ms\n","Error: 0.000703\n","\n","Kernel 3, block size 32x32, grid size 16x16\n","Kernel time: 0.258016 ms\n","Error: 0.000703\n"]}]},{"cell_type":"code","source":["!./HW3 in.pnm out.pnm 16 16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oz2IxpctzU-k","executionInfo":{"status":"ok","timestamp":1669279392619,"user_tz":-420,"elapsed":1372,"user":{"displayName":"Nam Vo","userId":"01521377105719415804"}},"outputId":"0a899de3-8a5a-4c93-d8d0-b1991ba32e3c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["**********GPU info**********\n","Name: Tesla T4\n","Compute capability: 7.5\n","Num SMs: 40\n","Max num threads per SM: 1024\n","Max num warps per SM: 32\n","GMEM: 15843721216 bytes\n","CMEM: 65536 bytes\n","L2 cache: 4194304 bytes\n","SMEM / one SM: 65536 bytes\n","****************************\n","\n","Image size (width x height): 512 x 512\n","\n","Kernel 1, block size 16x16, grid size 32x32\n","Kernel time: 0.460960 ms\n","Error: 0.000703\n","\n","Kernel 2, block size 16x16, grid size 32x32\n","Kernel time: 0.313344 ms\n","Error: 0.000703\n","\n","Kernel 3, block size 16x16, grid size 32x32\n","Kernel time: 0.239616 ms\n","Error: 0.000703\n"]}]},{"cell_type":"code","source":["!./HW3 in.pnm out.pnm 8 8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umKeaUO8zXUY","executionInfo":{"status":"ok","timestamp":1669279393344,"user_tz":-420,"elapsed":729,"user":{"displayName":"Nam Vo","userId":"01521377105719415804"}},"outputId":"833fa8e8-13ac-41d9-e82d-0ed7e8dcba25"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["**********GPU info**********\n","Name: Tesla T4\n","Compute capability: 7.5\n","Num SMs: 40\n","Max num threads per SM: 1024\n","Max num warps per SM: 32\n","GMEM: 15843721216 bytes\n","CMEM: 65536 bytes\n","L2 cache: 4194304 bytes\n","SMEM / one SM: 65536 bytes\n","****************************\n","\n","Image size (width x height): 512 x 512\n","\n","Kernel 1, block size 8x8, grid size 64x64\n","Kernel time: 0.804320 ms\n","Error: 0.000703\n","\n","Kernel 2, block size 8x8, grid size 64x64\n","Kernel time: 0.506336 ms\n","Error: 0.000703\n","\n","Kernel 3, block size 8x8, grid size 64x64\n","Kernel time: 0.447968 ms\n","Error: 0.000703\n"]}]},{"cell_type":"markdown","metadata":{"id":"XebMjR45-0Io"},"source":["Giải thích kết quả:\n","\n","- Việc dùng SMEM nhanh hơn so với không dùng vì SMEM có tốc độ truy xuất cao hơn so với truy xuất qua GMEM, hơn nữa việc dùng SMEM cũng sẽ hạn chế số lần truy xuất GMEM.\n","- Việc dùng CMEM nhanh hơn so với không dùng vì dữ liệu của filter không thay đổi trong suốt quá trình thực thi. CMEM có bộ nhớ const cache có độ trễ thấp. Trong warp các thread sẽ lấy dữ liệu lần lượt các phần tử từ cùng 1 filter, mỗi phần tử chỉ đọc 1 lần duy nhất và được broadcast cho toàn bộ các thread trong warp, từ đó làm giảm đáng kể thời gian thực thi."]}]}